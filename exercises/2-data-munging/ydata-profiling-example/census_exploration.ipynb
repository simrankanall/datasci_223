{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75bdb225-9ba6-479b-b15a-8fde07034146",
   "metadata": {},
   "source": [
    "## Pandas Profiling: USA Air Pollution Data\n",
    "Source of data: https://data.world/data-society/us-air-pollution-data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f376d03-b7de-4c38-9eaf-ad74dbfebca6",
   "metadata": {},
   "source": [
    "The autoreload instruction reloads modules automatically before code execution, which is helpful for the update below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b514dd38-2ebd-4c96-aed5-4e3695e20fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3ef034-d2d1-4e12-9c8d-7cd685bfe001",
   "metadata": {},
   "source": [
    "Make sure that we have the latest version of pandas-profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bcf2de2-58bf-4995-8cf7-3145322b45f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "\n",
    "%pip install -U ydata_profiling pandas jupyter ipywidgets json numpy pathlib\n",
    "\n",
    "# Skip this for now, we'll create HTML reports instead\n",
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d526f3-14fe-454e-8b9c-6662ceac81c3",
   "metadata": {},
   "source": [
    "# You might want to restart the kernel now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da73be69-6618-463b-8e5d-b8fd4e4bfdfb",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b33a26ed-4e1e-4689-93ce-fa0f98f48e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10288/1250497162.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "from ydata_profiling.utils.cache import cache_file\n",
    "from ydata_profiling.config import Dataset\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10288/770057977.py:7: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3107c65ac44a06ba941363c678870b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/ydata_profiling/model/correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(correlations={\"auto\": {\"calculate\": False}})`\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'could not convert string to float: ' Bachelors'')\n",
      "  warnings.warn(\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/seaborn/matrix.py:260: FutureWarning: Format strings passed to MaskedConstant are ignored, but in future may error or produce different behavior\n",
      "  annotation = (\"{:\" + self.fmt + \"}\").format(val)\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/ydata_profiling/model/missing.py:78: UserWarning: There was an attempt to generate the Heatmap missing values diagrams, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(missing_diagrams={\"Heatmap\": False}`)\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'could not convert string to float: '--'')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a04ac6cf7c84071b2a45c07010411e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a030446cef0a48c5ab3cf12277b8f5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3c53dbd738440d83234dafbe703a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "file_name = cache_file(\n",
    "    \"census_train.csv\",\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    ")\n",
    "\n",
    "# Names based on https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\n",
    "df = pd.read_csv(\n",
    "    file_name,\n",
    "    header=None,\n",
    "    index_col=False,\n",
    "    names=[\n",
    "        \"age\",\n",
    "        \"workclass\",\n",
    "        \"fnlwgt\",\n",
    "        \"education\",\n",
    "        \"education-num\",\n",
    "        \"marital-status\",\n",
    "        \"occupation\",\n",
    "        \"relationship\",\n",
    "        \"race\",\n",
    "        \"sex\",\n",
    "        \"capital-gain\",\n",
    "        \"capital-loss\",\n",
    "        \"hours-per-week\",\n",
    "        \"native-country\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Prepare missing values\n",
    "df = df.replace(\"\\\\?\", np.nan, regex=True)\n",
    "\n",
    "# Initialize the report\n",
    "profile = ProfileReport(df, title=\"Census Dataset\", explorative=True)\n",
    "\n",
    "# show column definition\n",
    "with open(\"census_column_definition.json\") as f:\n",
    "    definitions = json.load(f)\n",
    "\n",
    "profile.config.dataset = Dataset(\n",
    "    description='Predict whether income exceeds $50K/yr based on census data. Also known as \"Census Income\" dataset. Extraction was done by Barry Becker from the 1994 Census database. A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0)). Prediction task is to determine whether a person makes over 50K a year.',\n",
    "    copyright_year=\"1996\",\n",
    "    author=\"Ronny Kohavi and Barry Becker\",\n",
    "    creator=\"Barry Becker\",\n",
    "    url=\"https://archive.ics.uci.edu/ml/datasets/adult\",\n",
    ")\n",
    "profile.config.variables.descriptions = definitions\n",
    "\n",
    "# Only show the descriptions in the overview\n",
    "profile.config.show_variable_description = False\n",
    "\n",
    "profile.to_file(Path(\"./census_report.html\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7e1bf7-9891-4a8b-87e9-680225596f47",
   "metadata": {},
   "source": [
    "### Load and prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dab0b47-537d-4402-af71-1bdfd0cf6cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = cache_file(\n",
    "    \"pollution_us_2000_2016.csv\",\n",
    "    \"https://query.data.world/s/mz5ot3l4zrgvldncfgxu34nda45kvb\",\n",
    ")\n",
    "\n",
    "df = pd.read_csv(file_name, index_col=[0])\n",
    "\n",
    "# We will only consider the data from Arizone state for this example\n",
    "df = df[df[\"State\"] == \"Arizona\"]\n",
    "df[\"Date Local\"] = pd.to_datetime(df[\"Date Local\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4fc84f-6a82-43c7-b17f-24f1a56cb3e1",
   "metadata": {},
   "source": [
    "### Multi-entity time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01519464",
   "metadata": {},
   "source": [
    "The support to time series can be enabled by passing the parameter tsmode=True to the ProfileReport when its enabled, pandas profiling will try to identify time-dependent features using the feature's autocorrelation, which requires a sorted DataFrame or the definition of the `sortby` parameter.\n",
    "\n",
    "When a feature is identified as time series will trigger the following changes:\n",
    "   - the histogram will be replaced by a line plot\n",
    "   - the feature details will have a new tab with autocorrelation and partial autocorrelation plots\n",
    "   - two new warnings: `NON STATIONARY` and `SEASONAL` (which indicates that the series may have seasonality)\n",
    "\n",
    "In cases where the data has multiple entities,  as in this example, where we have different meteorological stations, each station can be interpreted as a time series, its necessary to filter the entities and profile each station separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc10f039",
   "metadata": {},
   "source": [
    "The following plot showcases the amount of data for each entity over time. In this case the data from the stations started being collected at the same period, and the data is collected hourly so they have the same amount of data per period.\n",
    "\n",
    "# VS Code may require `Jupyter Notebook Renderers` extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e613a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling.visualisation.plot import timeseries_heatmap\n",
    "\n",
    "timeseries_heatmap(dataframe=df, entity_column=\"Site Num\", sortby=\"Date Local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29a7e78-d52d-458d-ac9a-e509ffd373d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Return the profile per station\n",
    "# for group in df.groupby(\"Site Num\"):\n",
    "#     # Running 1 profile per station\n",
    "#     profile = ProfileReport(\n",
    "#         group[1],\n",
    "#         tsmode=True,\n",
    "#         sortby=\"Date Local\",\n",
    "#         # title=f\"Air Quality profiling - Site Num: {group[0]}\"\n",
    "#     )\n",
    "\n",
    "#     profile.to_file(f\"Ts_Profile_{group[0]}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f97ef64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d65bd690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8769/3031617755.py:7: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'census_column_definition.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/datasci_223/exercises/2-data-munging/usaairquality.ipynb Cell 18\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bvigilant-chainsaw-5gxw744g6f7qpw/workspaces/datasci_223/exercises/2-data-munging/usaairquality.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m profile \u001b[39m=\u001b[39m ProfileReport(df, title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCensus Dataset\u001b[39m\u001b[39m\"\u001b[39m, explorative\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bvigilant-chainsaw-5gxw744g6f7qpw/workspaces/datasci_223/exercises/2-data-munging/usaairquality.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# show column definition\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bvigilant-chainsaw-5gxw744g6f7qpw/workspaces/datasci_223/exercises/2-data-munging/usaairquality.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mcensus_column_definition.json\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bvigilant-chainsaw-5gxw744g6f7qpw/workspaces/datasci_223/exercises/2-data-munging/usaairquality.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     definitions \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bvigilant-chainsaw-5gxw744g6f7qpw/workspaces/datasci_223/exercises/2-data-munging/usaairquality.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m profile\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdataset \u001b[39m=\u001b[39m Dataset(\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bvigilant-chainsaw-5gxw744g6f7qpw/workspaces/datasci_223/exercises/2-data-munging/usaairquality.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m     description\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPredict whether income exceeds $50K/yr based on census data. Also known as \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCensus Income\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m dataset. Extraction was done by Barry Becker from the 1994 Census database. A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0)). Prediction task is to determine whether a person makes over 50K a year.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bvigilant-chainsaw-5gxw744g6f7qpw/workspaces/datasci_223/exercises/2-data-munging/usaairquality.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m     copyright_year\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m1996\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bvigilant-chainsaw-5gxw744g6f7qpw/workspaces/datasci_223/exercises/2-data-munging/usaairquality.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m     url\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://archive.ics.uci.edu/ml/datasets/adult\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bvigilant-chainsaw-5gxw744g6f7qpw/workspaces/datasci_223/exercises/2-data-munging/usaairquality.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'census_column_definition.json'"
     ]
    }
   ],
   "source": [
    "file_name = cache_file(\n",
    "    \"census_train.csv\",\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    ")\n",
    "\n",
    "# Names based on https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\n",
    "df = pd.read_csv(\n",
    "    file_name,\n",
    "    header=None,\n",
    "    index_col=False,\n",
    "    names=[\n",
    "        \"age\",\n",
    "        \"workclass\",\n",
    "        \"fnlwgt\",\n",
    "        \"education\",\n",
    "        \"education-num\",\n",
    "        \"marital-status\",\n",
    "        \"occupation\",\n",
    "        \"relationship\",\n",
    "        \"race\",\n",
    "        \"sex\",\n",
    "        \"capital-gain\",\n",
    "        \"capital-loss\",\n",
    "        \"hours-per-week\",\n",
    "        \"native-country\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Prepare missing values\n",
    "df = df.replace(\"\\\\?\", np.nan, regex=True)\n",
    "\n",
    "# Initialize the report\n",
    "profile = ProfileReport(df, title=\"Census Dataset\", explorative=True)\n",
    "\n",
    "# show column definition\n",
    "with open(\"census_column_definition.json\") as f:\n",
    "    definitions = json.load(f)\n",
    "\n",
    "profile.config.dataset = Dataset(\n",
    "    description='Predict whether income exceeds $50K/yr based on census data. Also known as \"Census Income\" dataset. Extraction was done by Barry Becker from the 1994 Census database. A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0)). Prediction task is to determine whether a person makes over 50K a year.',\n",
    "    copyright_year=\"1996\",\n",
    "    author=\"Ronny Kohavi and Barry Becker\",\n",
    "    creator=\"Barry Becker\",\n",
    "    url=\"https://archive.ics.uci.edu/ml/datasets/adult\",\n",
    ")\n",
    "profile.config.variables.descriptions = definitions\n",
    "\n",
    "# Only show the descriptions in the overview\n",
    "profile.config.show_variable_description = False\n",
    "\n",
    "profile.to_file(Path(\"./census_report.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048f9c35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
